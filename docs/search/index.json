[{"content":"问题复盘 责任人 不是我搞炸的，只是负责善后\n问题表现和原因 问题表现：Elasticsearch集群全部掉线，科研大数据赋能平台搜索功能不可用，Kibana页面打不开。\n原因：原153机器中的Elasticsearch部署方式为压缩包安装，存在机器重启后服务掉线隐患，因此需要重新部署为自启动服务。重新安装后，153机器中的新节点无法接入83机器中的集群，尝试重启83中的主节点后出现ES集群全部不可用的情况，尝试回退机器系统后153机器的原服务不能自动恢复，导致83机器中的集群无法正常工作。\n报错的解决：ES需要超过半数的集群启动才能启动，否则无法选举出主节点，配置中的init master在已经运行后再启动的集群上不生效。所以减少节点数量最好是逐渐减少。\n各时间节点（操作和恢复步骤及线上问题表现）  2月27号 尝试在153机器中部署新节点。 2月28号 153机器中的节点无法加入集群 16点尝试重启83机器中的ES服务，Elasticsearch服务掉线，科研大数据赋能平台搜索功能不可用。 17点开始回退机器系统。 3月1号 9点重启153机器中的旧服务。 10点30在153机器中部署新的自启动服务，并成功接入集群，科研大数据赋能平台搜索功能恢复正常。  后续避免措施 ES配置注意事项：  新建节点服务安装完不要启动！不要启动！启动会产生新的cluster uuid，与已有集群不一致，导致无法加入集群。如不慎启动，关闭服务后，删除node文件夹 新节点加入集群只需配置新节点的配置文件即可，证书密钥复制即可，重点配置elasticsearch.yml文件。  流程事项：  在不确定是否会对主服务产生影响的情况禁止操作。禁止重启83机器中的服务。 提前规划好操作方案，并整理成技术文档交由主管老师审核，审核通过后执行。  ","date":"2023-03-01T12:00:00Z","image":"https://wuyoudexiao.github.io/p/issue-es/cover_hu18cfcb466ca25429b480c33e8d5461b4_490997_120x120_fill_box_smart1_3.png","permalink":"https://wuyoudexiao.github.io/p/issue-es/","title":"ES集群的崩溃"},{"content":"起点  Look to those who walked before to lead those who walk after\n ","date":"2022-03-06T00:00:00Z","image":"https://wuyoudexiao.github.io/p/hello-world/cover_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://wuyoudexiao.github.io/p/hello-world/","title":"Hello World"},{"content":"Tars学习记录  参考官方文档 https://doc.tarsyun.com/#/default-index 如果本文内容与官方文档出现偏差以官方文档为准\n SpringBoot 客户端 调用方法 1.引入*.tars文件 tar文件放于resources文件夹下面\n1 2 3 4 5 6 7 8  module graph { interface Person{ string findPersonById(string id); string findShortPathByNumber(string type,string number1,string number2); string getLinkByName(string number,string type); }; };   2.修改pom.xml文件 pom文件中添加依赖与打包插件\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;!--tars--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.tencent.tars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tars-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.2\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;jar\u0026lt;/type\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt;   打包插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.tencent.tars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tars-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;tars2JavaConfig\u0026gt; \u0026lt;!-- tars文件位置 --\u0026gt; \u0026lt;tarsFiles\u0026gt; \u0026lt;tarsFile\u0026gt;${basedir}/src/main/resources/sda.tars\u0026lt;/tarsFile\u0026gt; \u0026lt;/tarsFiles\u0026gt; \u0026lt;!-- 源文件编码 --\u0026gt; \u0026lt;tarsFileCharset\u0026gt;UTF-8\u0026lt;/tarsFileCharset\u0026gt; \u0026lt;!-- 生成代码，PS：客户端调用，这里需要设置为false --\u0026gt; \u0026lt;servant\u0026gt;false\u0026lt;/servant\u0026gt; \u0026lt;!-- 生成源代码编码 --\u0026gt; \u0026lt;charset\u0026gt;UTF-8\u0026lt;/charset\u0026gt; \u0026lt;!-- 生成的源代码目录 --\u0026gt; \u0026lt;srcPath\u0026gt;${basedir}/src/main/java/\u0026lt;/srcPath\u0026gt; \u0026lt;!-- 生成源代码包前缀 --\u0026gt; \u0026lt;packagePrefixName\u0026gt;cn.edu.seu.matrix.tars\u0026lt;/packagePrefixName\u0026gt; \u0026lt;/tars2JavaConfig\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt;   3.执行mvn tars:tars2java 生成文件 mvn执行后在定义的目录里生成文件\n4.调用 在@service或者@Controller类中添加\n1 2 3 4  private CommunicatorConfig cfg = new CommunicatorConfig(); private Communicator communicator = CommunicatorFactory.getInstance().getCommunicator(cfg); private String ip_tars=\u0026#34;SERVER_IP\u0026#34;; // 在tars上运行的服务用 173 的，其余用机器地址 private final String tars_app_name=\u0026#34;SERVER_NAME\u0026#34;; // 举例 SciDataAnalysis.SocialNetwork   然后生成代理，调用方法\n1 2  PersonPrx proxy = communicator.stringToProxy(PersonPrx.class, tars_app_name + \u0026#34;.PersonObj@tcp -h \u0026#34; + ip_tars + \u0026#34; -t 60000 -p 27430 -e 0\u0026#34;); proxy.findPersonById(number)   服务端 提供服务方法 1. 写tars文件 tars文件的编写请参考官方文档\n 参考官方文档 https://doc.tarsyun.com/#/base/tars-protocol.md 如果本文内容与官方文档出现偏差以官方文档为准\n 2.修改pom.xml文件 pom文件中添加依赖与打包插件\n1 2 3 4 5 6  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.tencent.tars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tars-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.2\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;jar\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt;   打包插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.tencent.tars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tars-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;tars2JavaConfig\u0026gt; \u0026lt;!-- tars文件位置 --\u0026gt; \u0026lt;tarsFiles\u0026gt; \u0026lt;tarsFile\u0026gt;${basedir}/src/main/resources/socialNetwork.tars\u0026lt;/tarsFile\u0026gt; \u0026lt;/tarsFiles\u0026gt; \u0026lt;!-- 源文件编码 --\u0026gt; \u0026lt;tarsFileCharset\u0026gt;UTF-8\u0026lt;/tarsFileCharset\u0026gt; \u0026lt;!-- 生成服务端代码 --\u0026gt; \u0026lt;servant\u0026gt;true\u0026lt;/servant\u0026gt; \u0026lt;!-- 生成源代码编码 --\u0026gt; \u0026lt;charset\u0026gt;UTF-8\u0026lt;/charset\u0026gt; \u0026lt;!-- 生成的源代码目录 --\u0026gt; \u0026lt;srcPath\u0026gt;${basedir}/src/main/java\u0026lt;/srcPath\u0026gt; \u0026lt;!-- 生成源代码包前缀 --\u0026gt; \u0026lt;packagePrefixName\u0026gt;cn.edu.seu.socialNetwork\u0026lt;/packagePrefixName\u0026gt; \u0026lt;/tars2JavaConfig\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt;   3.执行mvn tars:tars2java 生成文件 mvn执行后在定义的目录里生成文件,其中Servant接口类是自动生成的\n4.实现 将Servant接口类实现一下 其中PersonObj与页面上的定义一致\n1 2 3  @TarsServant(\u0026#34;PersonObj\u0026#34;) public class PersonObj implements PersonServant { }   类中需要@Override所有的 方法\n5.定义服务 6.打包上传 基于Docker容器的TARS JAVA环境搭建 安装前准备 本教程需要预先安装Docker环境，所使用的IDE为IntelliJ IDEA。所有安装都基于Windows环境下。文中涉及到的目录均以 C:/User/xxx/ 写法表示\n获取Docker镜像 拉取最新的TARS容器（Java版）：\n1  docker pull tarscloud/tars:java   如果需要不同JDK版本的容器，可以基于Dockerfile来修改和构建自己的容器镜像（install.sh内容也要做相应修改）。由于该镜像未安装mysql，故还需要安装mysql镜像，以5.7版本为例。\n1 2  docker pull mysql:5.7   快速上手例程 本教程使用代码仓库中的 quickstart-server 和 quickerstart-client 例程作为搭建代码，可以先下载到本地使用IDEA打开。\n开发方式 使用docker镜像进行Tars相关的开发非常方便，例如可以把项目放置在某个本地目录下，如\nC:/Users/xxx/tars_data\n，再将该目录挂载到镜像的\n/data\n目录，这样就能在本地使用编辑器或IDE对项目文件进行开发。 如果需要进入Tars环境进行编译或测试，可以使用命令\ndocker exec\n进入容器内部查看。\n服务端配置 启动容器 首先执行下面的命令来启动TARS（Windows命令行不支持 \\ 命令换行），注意需要先在 C:/User/xxx/ 目录下新建目录 mysql_data 和 tars_data 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  docker run -d --name mysql \\ -e MYSQL_ROOT_PASSWORD=password \\ -p 3306:3306 \\ -v C:/User/xxx/mysql_data:/var/lib/mysql \\ mysql:5.7 --innodb_use_native_aio=0 docker run -d -it --name tars_java \\ --link mysql \\ --env DBIP=mysql \\ --env DBPort=3306 \\ --env DBUser=root \\ --env DBPassword=password \\ -p 3000:3000 \\ -p 18600:18600 \\ -v C:/Users/xxx/tars_data:/data \\ tarscloud/tars:java   待容器启动完毕，此时可以在本地访问\nhttp://127.0.0.1:3000\n查看TARS的web管理界面了。\n注：如果你使用的mysql不是5.6的版本，可能需要调整docker run的参数\nJava 本地单元测试方法  参考 https://tarscloud.github.io/TarsDocs/dev/tarsjava/tarsspringboot-shi-yong-shuo-ming.html {.is-info}\n  拷贝node生成的模板文件到本地（在服务器 tasnode/data/服务名/conf 目录下） 修改其中每个servant的启动ip和端口文本地ip端口 配置启动参数 -Dconfig=(模板路径) 通过ide启动MainClass  ","date":"2021-09-02T16:00:00Z","image":"https://wuyoudexiao.github.io/p/study-tars/tars_hu875a888cf5d5e3780616d87f4a390bc1_55883_120x120_fill_box_smart1_3.png","permalink":"https://wuyoudexiao.github.io/p/study-tars/","title":"Tars学习记录"},{"content":"ElasticSearch学习记录 数据类型 基础类型 字符串  String : 高版本的ES已经停用 text : 当一个字段是要被全文搜索的使用text类型。设置text类型以后，字段内容会被分析，在生成倒排索引，字符串会被分析器分成一个一个词项。text类型的字段不用于排序，很少用于聚合。 keyword : 适用于索引结构化的字段。如果字段需要进行过滤、排序、聚合需要采用keyword字段。keyword类型的字段只能通过精确值搜索到。  日期 date类型，需要注意：\n Elasticsearch采用UTC时区，与北京时间相差8小时，同步时需要注明时区。 默认格式是 strict_date_optional_time||epoch_millis 只接受年月日必须是4位、2位、2位表示，不足两位用0补齐的字符串日期或者long型数字的毫秒时间戳。 可以指定format使得取时间时是按照固定格式。  整数 在满足需求的情况下，尽可能选择范围小的数据类型。\n   类型 取值范围     byte -128~127   short -32768~32767   integer -231~231-1   long -263~263-1    高级类型 数组 可以支持字符数组，整数数组，对象数组。不支持元素为多个数据类型！\n对象 JSON对象，包含嵌套的对象。\n嵌套 Nested类型允许独立的索引每一个对象，对性能的影响较大。\nIk分词 与 pinyin分词  导入字典 导入研究人员名称 导入停用词 自动化更新字典  算法（BM25）优化 用$D$代指计算文档，$Q$指的是用户输入的搜索关键词，将$Q$分词后得到若干词$q_i$，计算得到的分数为$score(D,Q)$如下。 $$ score(D,Q) = \\sum_{i=1}^n IDF(q_i) \\cdot \\frac{f(q_i,D)\\cdot(k_1+1)}{f(q_i,D)+k_1 \\cdot (1-b+b\\cdot \\frac{\\left\\vert D\\right\\vert}{avgdl})} $$\n在公式中有两个常数参数$b$和$k_1$。其中参数$b$的作用是调整文档长度对相关性影响的大小。$b$越大，文档长度的对相关性得分的影响越大，反之越小。参数$k_1$的作用是调节$q_i$增加时，得分增加的幅度。经过实践验证，通常的系统中选择$b = 0.75,k=2$可以获得较好的效果。\nQuery DSL 1. 采用multi_match匹配 最简单的匹配方式，获得的结果难以满足要求。\n1 2 3 4 5 6 7 8 9 10  { \u0026#34;query\u0026#34;:{ \u0026#34;multi_match\u0026#34;:{ \u0026#34;query\u0026#34;: \u0026#34;search_text\u0026#34;, \u0026#34;fields\u0026#34;:[ \u0026#34;f1\u0026#34;,\u0026#34;f2\u0026#34; ] } } }   2. 采用bool查询 添加筛选的查询方式。提供must，should，must_not，filter四种方式组合。\n must必须满足，非直接过滤，参与评分。 should在有must的情况下无需满足，无must的情况下必须满足至少一个。默认参与评分，可以选择最少满足个数与是否参与评分。 must_not与filter为过滤器，不参与评分。  1 2 3 4 5 6 7 8 9 10 11 12 13  { \u0026#34;query\u0026#34;:{ \u0026#34;bool\u0026#34;:{ \u0026#34;should\u0026#34;:[ {\u0026#34;match\u0026#34;:{\u0026#34;f1\u0026#34;:\u0026#34;search_text\u0026#34;}}, {\u0026#34;match\u0026#34;:{\u0026#34;f2\u0026#34;:\u0026#34;search_text\u0026#34;}} ], \u0026#34;filter\u0026#34;:[ {\u0026#34;range\u0026#34;:{\u0026#34;date\u0026#34;:{\u0026#34;gte\u0026#34;:\u0026#34;2010-01-01\u0026#34;}}}, ] } } }   3. 采用match_phrase提高权重 解决搜索经常出现搜索结果和搜索关键词不是连续匹配的这个问题。match_phrase 要求必须命中所有分词，并且返回的文档命中的词也要按照查询短语的顺序，词的间距可以使用 slop 设置。同时使用 match 与 match_phrase 查询语句，这样相当于 match_pharse 提高了搜索短语顺序的权重，使得能够顺序匹配到的文档相关性评分更高。设置索引mappings时，给 tags 字段设置上 position_increment_gap （默认100），来增加数组元素之间的位置，此位置要超过查询所使用的 slop。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;query\u0026#34;:{ \u0026#34;bool\u0026#34;:{ \u0026#34;should\u0026#34;:[ {\u0026#34;match\u0026#34;:{\u0026#34;f1\u0026#34;:\u0026#34;search_text\u0026#34;}}, {\u0026#34;match_phrase\u0026#34;:{\u0026#34;f1\u0026#34;:{\u0026#34;query\u0026#34;:\u0026#34;search_text\u0026#34;,\u0026#34;slop\u0026#34;:5}}}, {\u0026#34;match\u0026#34;:{\u0026#34;f2\u0026#34;:\u0026#34;search_text\u0026#34;}} ], \u0026#34;filter\u0026#34;:[ {\u0026#34;range\u0026#34;:{\u0026#34;date\u0026#34;:{\u0026#34;gte\u0026#34;:\u0026#34;2010-01-01\u0026#34;}}}, ] } } }   4. 采用boost调整查询语句的权重 查询时可以用 boost 配置来增加权重。设置后，查询语句的得分等于默认得分乘以 boost。\n  数据质量高的字段可以相应提高权重；\n  match_phrase 语句的权重应该高于相应字段 match 查询的权重，因为文档中按顺序匹配的短语可能数量不会太多，但是查询关键词被分词后的词语将会很多，match的得分将会比较高，则 match 的得分将会冲淡 match_phrase 的影响；\n  在 mappings 设置中，可以针对字段设置权重，查询时不用再针对字段使用 boost 设置。\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;query\u0026#34;:{ \u0026#34;bool\u0026#34;:{ \u0026#34;should\u0026#34;:[ {\u0026#34;match\u0026#34;:{\u0026#34;f1\u0026#34;:\u0026#34;search_text\u0026#34;}}, {\u0026#34;match_phrase\u0026#34;:{\u0026#34;f1\u0026#34;:{\u0026#34;query\u0026#34;:\u0026#34;search_text\u0026#34;,\u0026#34;slop\u0026#34;:5,\u0026#34;boost\u0026#34;:10}}}, {\u0026#34;match\u0026#34;:{\u0026#34;f2\u0026#34;:\u0026#34;search_text\u0026#34;}} ], \u0026#34;filter\u0026#34;:[ {\u0026#34;range\u0026#34;:{\u0026#34;date\u0026#34;:{\u0026#34;gte\u0026#34;:\u0026#34;2010-01-01\u0026#34;}}}, ] } } }   5.采用function_score增加评分因素 为了增加实际项目中时间，对文档评分的影响往往比较复杂，不仅仅时简单的计算相关度，还需要根据字段对评分进行一定的计算。function_score可以解决以下问题。\n 时间影响：距今越近的文档具有更高的评分； 收藏影响：收藏数量更多的文档具有更高的评分； 完整性影响：完整的文档比残缺的文档具有更高的评分； 推广影响：被推广的文档具有更高的评分； ······  在数据搭建阶段我们就能确定这些因素的权重，并且和查询关键词没有什么关系。称之为静态评分，一般具有以下特点：\n 稳定性：不要经常有大幅度的变动，如果大幅度变化会导致用户搜索相同的关键词过段时间出来的结果会不同； 连续性：相似静态评分的情况下，文档的相关的等其他因素可以充分发挥作用。 区分度：在连续稳定的情况下，应该有一定的区分度，也即分值的间隔应该合理。如果有 1000 份文档，在 1.0 分到 1.001 分之间，这其实是没有实际意义的，因为对文档排名的影响太少了。  在ES中有以下的方式实现这些因素对排名的影响：\n script_score，这是最灵活的方式，可以自定义算法； weight，乘以一个权重数值； random_score，随机分数； field_value_factor，使用某个字段来影响总分数； decay fucntion，包括gauss、exp、linear三种衰减函数。  filed_value_factor 1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;query\u0026#34;:{ \u0026#34;function_score\u0026#34;:{ \u0026#34;field_value_factor\u0026#34;:{ \u0026#34;field\u0026#34;: \u0026#34;collection_num\u0026#34;, \u0026#34;factor\u0026#34;: 1, \u0026#34;modifier\u0026#34;: \u0026#34;log2p\u0026#34;, \u0026#34;missing\u0026#34;: 0 } } } }   modifier支持的函数有：\n none：$score^* = score \\cdot collectionNum$ log1p：$score^* = score \\cdot log(1 + factor \\cdot collectionNum)$ log2p：$score^* = score \\cdot log(2 + factor \\cdot collectionNum)$ ln : $score^* = score \\cdot ln(factor \\cdot collectionNum)$ ln1p : $score^* = score \\cdot ln(1 + factor \\cdot collectionNum)$ ln2p : $score^* = score \\cdot ln(2 + factor \\cdot collectionNum)$ square sqrt reciprocal  除了modifier还有boost_mode可以改变对评分影响的模式，默认的改变评分方式为乘积，如果将boost_mode设定为sum那么将大大弱化这些因素对结果的影响。最后还可以加上max_boost参数来限定最大的boost值。missing参数还可以用来降低残缺文档的评分，把 missing 设置为小于1的数值即可。\ndecay function 衰减函数可以实现平滑过渡，使距离某个点越近的文档分数越高，越远的分数越低。使用衰减函数很容易实现时间越近的文档得分就越高的场景。ES提供了三个衰减函数，我们先来看一下这三种衰减函数的差别。\n linear，是两条线性函数，从直线和横轴相交处以外，评分都为0； exp，是指数函数，先剧烈的衰减，然后缓慢衰减； guass，高斯衰减是最常用的，先缓慢再剧烈再缓慢，scale相交的点附近衰减比较剧烈。  当我们想选取一定范围内的结果，或者一定范围内的结果比较重要时，例如某个时间、地域（圆形）、价格范围内，都可以使用高斯衰减函数。高斯衰减函数有4个参数可以设置\n origin：中心点，或字段可能的最佳值，落在原点 origin 上的文档评分 _score 为满分 1.0 ； scale：衰减率，即一个文档从原点 origin 下落时，评分 _score 改变的速度； decay：从原点 origin 衰减到 scale 所得的评分 _score ，默认值为 0.5 ； offset：以原点 origin 为中心点，为其设置一个非零的偏移量 offset 覆盖一个范围，而不只是单个原点。在范围 -offset \u0026lt;= origin \u0026lt;= +offset 内的所有评分 _score 都是 1.0 。  假定搜索引擎中三年内的文档会比较重要，三年之前的信息价值降低，就可以选择 origin 为今天，scale 为三年，decay 为 0.5，offset 为三个月。\n6.采用script_sort进行排序 基于脚本的排序 允许根据自定义脚本进行排序，下面是一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  GET /_search { \u0026#34;query\u0026#34; : { \u0026#34;term\u0026#34; : { \u0026#34;user\u0026#34; : \u0026#34;kimchy\u0026#34; } }, \u0026#34;sort\u0026#34; : { \u0026#34;_script\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;number\u0026#34;, \u0026#34;script\u0026#34; : { \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;doc[\u0026#39;field_name\u0026#39;].value * params.factor\u0026#34;, \u0026#34;params\u0026#34; : { \u0026#34;factor\u0026#34; : 1.1 } }, \u0026#34;order\u0026#34; : \u0026#34;asc\u0026#34; } } }   如何使用脚本 1 2 3 4 5  \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;source\u0026#34; | \u0026#34;id\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;params\u0026#34;: { ... } }   \u0026ldquo;lang\u0026rdquo;：编写脚本所用的语言，默认为painless。 \u0026ldquo;source\u0026rdquo; | \u0026ldquo;id\u0026rdquo;：可以指定为内联脚本或存储脚本的脚本本身。 \u0026ldquo;params\u0026rdquo;：应传递到脚本中的任何命名参数。\n人员搜索排序脚本 当前ES中存储的自定义人员排序脚本，根据人员关键词权重进行排序。\n","date":"2021-06-02T14:28:00Z","image":"https://wuyoudexiao.github.io/p/study-es/es-%E8%A1%B0%E5%87%8F%E5%87%BD%E6%95%B0_hu1c76feb9b2706ad14d03897c9357b434_29245_120x120_fill_q75_box_smart1.jpg","permalink":"https://wuyoudexiao.github.io/p/study-es/","title":"ElasticSearch学习记录"}]